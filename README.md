# ğŸ•¸ï¸ Web Scraping Suite for Nepal-Based Tech & School Data

A collection of Python-based web scrapers tailored to Nepal-specific websites for extracting tech company and school data. It supports both paginated and infinite scrolling (lazy loading) pages using Selenium.

---

## ğŸ§© Features

- ğŸ” Paginated scraping for:
  - Tech companies (TechBehemoths)
  - Schools in Kathmandu (EduSanjal)
- ğŸ” Infinite scroll scraping for:
  - Schools in Lalitpur (CollegeNP)
- ğŸ“„ Clean Excel output using `pandas`
- âš™ï¸ Modular, well-commented, and extensible codebase
- ğŸ›¡ï¸ Error handling and browser simulation with user-agent headers

---

## ğŸ“¦ Requirements

Install dependencies with:

```bash
pip install -r requirements.txt
```

### ğŸ§¾ `requirements.txt`

```text
beautifulsoup4==4.13.4
certifi==2025.7.9
charset-normalizer==3.4.2
idna==3.10
numpy==2.3.1
pandas==2.3.1
python-dateutil==2.9.0.post0
pytz==2025.2
requests==2.32.4
six==1.17.0
soupsieve==2.7
typing_extensions==4.14.1
tzdata==2025.2
urllib3==2.5.0
```

> âš ï¸ **If using the lazyloading scrapping script**, make sure you also install:
> 
> - `selenium`
> - ChromeDriver (installed and added to your system `PATH`)

---

## ğŸš€ Usage

Each script runs independently. Use the following commands:

### ğŸ¢ TechBehemoths Company Scraper

```bash
python static_page_scraping.py
```

- **Output:** `Companies_in_nepal.xlsx`

---

### ğŸ« EduSanjal School Scraper

```bash
python paginated_scrapping.py
```

- **Output:** `kathmandu_schools.xlsx`

---

### ğŸŒ€ CollegeNP Infinite Scroll Scraper

```bash
python scrapping_for_lazyloading.py
```

- **Output:** `Schools_in_lalitpur.xlsx`

---

## ğŸ“ Project Structure

```text
.
â”œâ”€â”€ static_page_scrapping.py        # Single-page scraper for company listings on TechBehemoths
â”œâ”€â”€ pagianted_scrapping.py          # Scrapes paginated schools from EduSanjal
â”œâ”€â”€ scrapping_for_lazyloading.py    # Scrapes lazy-loaded schools from CollegeNP using Selenium
â”œâ”€â”€ requirements.txt                # All Python dependencies
â””â”€â”€ README.md                       # This file
```

---

## ğŸ”§ How It Works

### ğŸ§­ Static Scrapers (TEduSanjal)

- Uses `requests` and `BeautifulSoup`
- Scrapes data from a single, non-paginated HTML page
- Parses company listings directly without pagination handling

### ğŸ§­ Paginated Scrapers (Edusanjal)

- Uses `requests` and `BeautifulSoup`
- Detects pagination and follows "Next" links
- Parses HTML to extract structured data

### ğŸ”„ Infinite Scroll Scraper (CollegeNP)

- Uses `Selenium` WebDriver
- Simulates browser scroll to load content
- Waits dynamically for elements to appear before extraction

---

## ğŸ“Š Output Format

Most scripts generate Excel files with:
- ğŸ“Œ Name
- ğŸ“ Address & location
- â˜ï¸ Contact information

---

## ğŸ› ï¸ Customization

You can adapt the scripts to:
- Scrape other websites
- Add or remove data fields
- Export to Excel or CSV or JSON
- Include filters (e.g., by location or type)

---

## ğŸ™Œ Acknowledgments

- [TechBehemoths](https://techbehemoths.com) â€“ Tech directory
- [EduSanjal](https://edusanjal.com) â€“ School listings
- [CollegeNP](https://collegenp.com) â€“ College portal
- ğŸ `BeautifulSoup` â€“ HTML parser
- ğŸ¤– `Selenium` â€“ Browser automation
- ğŸ“Š `pandas` â€“ Data analysis and Excel export

---


## ğŸ¤ Contributing

Contributions are welcome! Fork the repo and submit a pull request. Suggestions, bug fixes, and improvements are appreciated.
